{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-22T13:59:45.769718Z","iopub.execute_input":"2021-12-22T13:59:45.770381Z","iopub.status.idle":"2021-12-22T13:59:45.796541Z","shell.execute_reply.started":"2021-12-22T13:59:45.770260Z","shell.execute_reply":"2021-12-22T13:59:45.795857Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Conv2D 적용하기\n* Conv2D() 를 모델에 적용 시에는 반드시 입력은 배치 크기를 제외하고 3차원이 되어야 함(즉 배치를 포함하면 4차원)  ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\nfrom tensorflow.keras.models import Model\n\ninput_tensor = Input(shape=(28, 28, 1))\nx = Conv2D(filters=4, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\nprint('x type:', type(x), 'x:', x)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T08:50:44.815702Z","iopub.execute_input":"2021-12-24T08:50:44.816026Z","iopub.status.idle":"2021-12-24T08:50:52.305741Z","shell.execute_reply.started":"2021-12-24T08:50:44.815991Z","shell.execute_reply":"2021-12-24T08:50:52.304983Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Pooling 적용하기","metadata":{}},{"cell_type":"code","source":"input_tensor = Input(shape=(28, 28, 1))\nx = Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\nx = MaxPooling2D(2)(x)\nprint(x)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T17:46:09.628251Z","iopub.execute_input":"2021-12-22T17:46:09.628500Z","iopub.status.idle":"2021-12-22T17:46:09.648532Z","shell.execute_reply.started":"2021-12-22T17:46:09.628472Z","shell.execute_reply":"2021-12-22T17:46:09.647413Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### CNN 모델 생성","metadata":{}},{"cell_type":"code","source":"input_tensor = Input(shape=(28, 28, 1))\nx = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor) # (3 x 3 x 1 x 32 + 32{bias})\nx = Conv2D(filters=64, kernel_size=3, activation='relu')(x) # (3 x 3x 32 x 64 + 64 = 18496)\nx = MaxPooling2D(2)(x)\n\nmodel = Model(inputs=input_tensor, outputs=x)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T17:46:12.897528Z","iopub.execute_input":"2021-12-22T17:46:12.898063Z","iopub.status.idle":"2021-12-22T17:46:12.932289Z","shell.execute_reply.started":"2021-12-22T17:46:12.898024Z","shell.execute_reply":"2021-12-22T17:46:12.931621Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten\n# Convolutional Layer\ninput_tensor = Input(shape=(28, 28, 1))\nx = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\nx = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\nx = MaxPooling2D(2)(x)\n\n# Classification을 위한 Fully Connected Layer\n# 3차원으로 되어있는 Feature map 결과를 Fully Connected 연결하기 위해서는 Flatten()을 적용해야함. \nx = Flatten()(x)\nx = Dense(100, activation='relu')(x) # 바로 softmax layer에 붙이면 정보가 많이 손실될 수 있어서 중간에 하나정도 dense layer를 넣어준다.\noutput = Dense(10, activation='softmax')(x)\nmodel = Model(inputs=input_tensor, outputs=output)\nmodel.summary()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-22T17:46:15.449725Z","iopub.execute_input":"2021-12-22T17:46:15.450516Z","iopub.status.idle":"2021-12-22T17:46:15.526941Z","shell.execute_reply.started":"2021-12-22T17:46:15.450467Z","shell.execute_reply":"2021-12-22T17:46:15.523819Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Fashion MNIST 데이터 전처리후 모델 학습","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.datasets import fashion_mnist\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n# 전체 6만개 데이터 중, 5만개는 학습 데이터용, 1만개는 테스트 데이터용으로 분리\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\ndef get_preprocessed_data(images, labels):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    images = np.array(images/255.0, dtype=np.float32)\n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\n# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \ndef get_preprocessed_ohe(images, labels):\n    images, labels = get_preprocessed_data(images, labels)\n    # OHE 적용 \n    oh_labels = to_categorical(labels)\n    return images, oh_labels\n\n# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \ndef get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n    \n    # 학습 데이터를 검증 데이터 세트로 다시 분리\n    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n    \n    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n\n\n# Fashion MNIST 데이터 재 로딩 및 전처리 적용하여 학습/검증/데이터 세트 생성. \n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\nprint(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\nprint(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T17:46:18.580321Z","iopub.execute_input":"2021-12-22T17:46:18.580615Z","iopub.status.idle":"2021-12-22T17:46:21.636231Z","shell.execute_reply.started":"2021-12-22T17:46:18.580585Z","shell.execute_reply":"2021-12-22T17:46:21.635437Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.metrics import Accuracy\n\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-22T17:46:25.937131Z","iopub.execute_input":"2021-12-22T17:46:25.937624Z","iopub.status.idle":"2021-12-22T17:46:25.953772Z","shell.execute_reply.started":"2021-12-22T17:46:25.937588Z","shell.execute_reply":"2021-12-22T17:46:25.953086Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T17:46:28.307097Z","iopub.execute_input":"2021-12-22T17:46:28.307890Z","iopub.status.idle":"2021-12-22T17:47:51.027734Z","shell.execute_reply.started":"2021-12-22T17:46:28.307849Z","shell.execute_reply":"2021-12-22T17:47:51.026982Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### 모델 성능 평가","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_history(history):\n    plt.plot(history.history['accuracy'], label='train')\n    plt.plot(history.history['val_accuracy'], label='valid')\n    plt.legend()\n    \nshow_history(history)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T17:49:01.654236Z","iopub.execute_input":"2021-12-22T17:49:01.654511Z","iopub.status.idle":"2021-12-22T17:49:01.897124Z","shell.execute_reply.started":"2021-12-22T17:49:01.654483Z","shell.execute_reply":"2021-12-22T17:49:01.896445Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# 테스트 데이터 세트로 모델 성능 검증\nmodel.evaluate(test_images, test_oh_labels, batch_size=256, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T17:50:28.774187Z","iopub.execute_input":"2021-12-22T17:50:28.774496Z","iopub.status.idle":"2021-12-22T17:50:29.105696Z","shell.execute_reply.started":"2021-12-22T17:50:28.774458Z","shell.execute_reply":"2021-12-22T17:50:29.105024Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Dropout을 적용하여 Fully Connected Layer의 오버피팅 조정\n* CNN은 일반적으로 Dense Layer보다는 파라미터수(weight 수) 작음\n* 하지만 많은 Filter 들을 적용하고 이를  Fully Connected Layer로 연결 시 파라미터 수가 늘어남. \n* Flatten() 이후 Dropout을 적용하여 특정 비율로 FC Layer 연결을 누락 적용. ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten, Dropout\n\ninput_tensor = Input(shape=(28, 28, 1))\nx = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\nx = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\nx = MaxPooling2D(2)(x)\n\nx = Flatten()(x)\nx = Dropout(rate=0.5)(x)\nx = Dense(100, activation='relu')(x)\noutput = Dense(10, activation='softmax')(x)\nmodel = Model(inputs=input_tensor, outputs=output)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T17:53:22.829291Z","iopub.execute_input":"2021-12-22T17:53:22.829860Z","iopub.status.idle":"2021-12-22T17:53:22.881595Z","shell.execute_reply.started":"2021-12-22T17:53:22.829824Z","shell.execute_reply":"2021-12-22T17:53:22.880938Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T17:54:22.075182Z","iopub.execute_input":"2021-12-22T17:54:22.075440Z","iopub.status.idle":"2021-12-22T17:55:44.646968Z","shell.execute_reply.started":"2021-12-22T17:54:22.075412Z","shell.execute_reply":"2021-12-22T17:55:44.646132Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"show_history(history)\nmodel.evaluate(test_images, test_oh_labels, batch_size=256, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T17:55:53.469190Z","iopub.execute_input":"2021-12-22T17:55:53.469951Z","iopub.status.idle":"2021-12-22T17:55:53.934952Z","shell.execute_reply.started":"2021-12-22T17:55:53.469915Z","shell.execute_reply":"2021-12-22T17:55:53.934262Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n\ndef create_model():\n    input_tensor = Input(shape=(28, 28, 1))\n    x = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\n    x = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\n    x = MaxPooling2D(2)(x)\n\n    x = Dropout(rate=0.5)(x)\n    x = Flatten()(x)\n    x = Dropout(rate=0.5)(x)\n    x = Dense(200, activation='relu')(x)\n    X = Dropout(rate=0.2)(x)\n    output = Dense(10, activation='softmax')(x)\n    model = Model(inputs=input_tensor, outputs=output)\n    model.summary()\n    \n    return model\n\nmodel = create_model()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T17:57:03.425583Z","iopub.execute_input":"2021-12-22T17:57:03.426239Z","iopub.status.idle":"2021-12-22T17:57:03.676391Z","shell.execute_reply.started":"2021-12-22T17:57:03.426196Z","shell.execute_reply":"2021-12-22T17:57:03.675658Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T17:57:15.035070Z","iopub.execute_input":"2021-12-22T17:57:15.035913Z","iopub.status.idle":"2021-12-22T17:58:37.061345Z","shell.execute_reply.started":"2021-12-22T17:57:15.035869Z","shell.execute_reply":"2021-12-22T17:58:37.060662Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"show_history(history)\nmodel.evaluate(test_images, test_oh_labels, batch_size=256, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T17:58:40.397381Z","iopub.execute_input":"2021-12-22T17:58:40.398007Z","iopub.status.idle":"2021-12-22T17:58:40.849994Z","shell.execute_reply.started":"2021-12-22T17:58:40.397968Z","shell.execute_reply":"2021-12-22T17:58:40.849072Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### 입력 이미지는 배치를 포함하여 4차원이 되어야 함(즉 배치를 제외하면 3차원)\n* Conv2D()는 입력으로 배치를 제외하고 3차원 입력이 되어야 함. \n* 하지만 2차원으로 입력해도 Input(shape=(28, 28, 1)) 에서 3차원으로 변경함. \n* 명확하게는 2차원 Grayscale이미지더라도 입력 numpy 이미지 배열에서 배치를 제외한 3차원 입력을 만들어 주는게 좋음. ","metadata":{}},{"cell_type":"code","source":"(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\nprint('before reshape:', train_images.shape, test_images.shape)\ntrain_images = np.reshape(train_images, (60000, 28, 28, 1))\ntest_images = np.reshape(test_images, (10000, 28, 28, 1))\nprint('after reshape:', train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n\n(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\nprint(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T18:00:42.128145Z","iopub.execute_input":"2021-12-22T18:00:42.128414Z","iopub.status.idle":"2021-12-22T18:00:42.809134Z","shell.execute_reply.started":"2021-12-22T18:00:42.128383Z","shell.execute_reply":"2021-12-22T18:00:42.808424Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\nmodel = create_model()\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T18:01:39.753420Z","iopub.execute_input":"2021-12-22T18:01:39.753747Z","iopub.status.idle":"2021-12-22T18:03:02.409943Z","shell.execute_reply.started":"2021-12-22T18:01:39.753710Z","shell.execute_reply":"2021-12-22T18:03:02.409207Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"show_history(history)\nmodel.evaluate(test_images, test_oh_labels, batch_size=256, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T18:03:11.128246Z","iopub.execute_input":"2021-12-22T18:03:11.128493Z","iopub.status.idle":"2021-12-22T18:03:11.723833Z","shell.execute_reply.started":"2021-12-22T18:03:11.128465Z","shell.execute_reply":"2021-12-22T18:03:11.723131Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stride가 1이고 Padding이 없는 경우\n* I는 입력 Feature Map의 크기, F는 Filter의 크기(Kernel size), P는 Padding(정수), S는 Strides(정수)\n* O = (I - F + 2P)/2 + 1 = (5 - 3 + 0 )/1 + 1 = 3","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\nfrom tensorflow.keras.models import Model\n\ninput_tensor = Input(shape=(5, 5, 1))\nx = Conv2D(filters=1, kernel_size=3, strides=1)(input_tensor)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:00:14.235576Z","iopub.execute_input":"2021-12-24T06:00:14.235989Z","iopub.status.idle":"2021-12-24T06:00:21.120218Z","shell.execute_reply.started":"2021-12-24T06:00:14.235883Z","shell.execute_reply":"2021-12-24T06:00:21.119178Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Stride가 1이고 Padding이 1인 경우\n* O = (I - F + 2P)/2 + 1 = (5 - 3 + 2 )/1 + 1 = 5","metadata":{}},{"cell_type":"code","source":"input_tensor = Input(shape=(5, 5, 1))\nx = Conv2D(filters=1, kernel_size=3, strides=1, padding='same')(input_tensor)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T08:51:00.961850Z","iopub.execute_input":"2021-12-24T08:51:00.962428Z","iopub.status.idle":"2021-12-24T08:51:00.981307Z","shell.execute_reply.started":"2021-12-24T08:51:00.962389Z","shell.execute_reply":"2021-12-24T08:51:00.980306Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# ZeroPadding2D Layer를 이용하여 padding을 수동으로 적용. \nfrom tensorflow.keras.layers import ZeroPadding2D\n\ninput_tensor = Input(shape=(5, 5, 1))\npadded_input = ZeroPadding2D(padding=1)(input_tensor)\nprint('shape after padding:', padded_input.shape)\nx = Conv2D(filters=1, kernel_size=3, strides=1)(padded_input)\nprint('x.shape:', x.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-24T08:51:03.393092Z","iopub.execute_input":"2021-12-24T08:51:03.393521Z","iopub.status.idle":"2021-12-24T08:51:03.426416Z","shell.execute_reply.started":"2021-12-24T08:51:03.393490Z","shell.execute_reply":"2021-12-24T08:51:03.424580Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Stride가 2이고 Padding이 없는 경우 \n* O = (I - F + 2P)/2 + 1 = (5 - 3)/2 + 1 = 2","metadata":{}},{"cell_type":"code","source":"input_tensor = Input(shape=(5, 5, 1))\nx = Conv2D(filters=1, kernel_size=3, strides=2)(input_tensor)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T08:51:08.018347Z","iopub.execute_input":"2021-12-24T08:51:08.019580Z","iopub.status.idle":"2021-12-24T08:51:08.038145Z","shell.execute_reply.started":"2021-12-24T08:51:08.019513Z","shell.execute_reply":"2021-12-24T08:51:08.037220Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Stride가 2이고 Padding은 1 적용\n* O = (I - F + 2P)/2 + 1 = (5 - 3 + 2)/2 + 1 = 3","metadata":{}},{"cell_type":"code","source":"input_tensor = Input(shape=(5, 5, 1))\npadded_input = ZeroPadding2D(padding=1)(input_tensor)\nprint('shape after padding:', padded_input.shape)\nx = Conv2D(filters=1, kernel_size=3, strides=2)(padded_input)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T08:51:10.337513Z","iopub.execute_input":"2021-12-24T08:51:10.338002Z","iopub.status.idle":"2021-12-24T08:51:10.364525Z","shell.execute_reply.started":"2021-12-24T08:51:10.337964Z","shell.execute_reply":"2021-12-24T08:51:10.363349Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### 입력이 6X6에서 Stride가 2 적용\n* O = (I - F + 2P)/2 + 1 = (6 - 3 + 0)/2 + 1 = 2.5 = 2","metadata":{}},{"cell_type":"code","source":"input_tensor = Input(shape=(6, 6, 1))\nx = Conv2D(filters=1, kernel_size=3, strides=2)(input_tensor)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T08:51:12.485822Z","iopub.execute_input":"2021-12-24T08:51:12.486198Z","iopub.status.idle":"2021-12-24T08:51:12.505431Z","shell.execute_reply.started":"2021-12-24T08:51:12.486162Z","shell.execute_reply":"2021-12-24T08:51:12.504576Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"input_tensor = Input(shape=(6, 6, 1))\nx = Conv2D(filters=1, kernel_size=3, strides=2, padding='same')(input_tensor)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T08:51:14.647454Z","iopub.execute_input":"2021-12-24T08:51:14.648091Z","iopub.status.idle":"2021-12-24T08:51:14.666889Z","shell.execute_reply.started":"2021-12-24T08:51:14.648050Z","shell.execute_reply":"2021-12-24T08:51:14.665806Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"input_tensor = Input(shape=(6, 6, 1))\npadded_input = ZeroPadding2D(padding=1)(input_tensor)\nx = Conv2D(filters=1, kernel_size=3, strides=2, padding='valid')(padded_input)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T08:51:16.988052Z","iopub.execute_input":"2021-12-24T08:51:16.988643Z","iopub.status.idle":"2021-12-24T08:51:17.010215Z","shell.execute_reply.started":"2021-12-24T08:51:16.988601Z","shell.execute_reply":"2021-12-24T08:51:17.009267Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"input_tensor = Input(shape=(6, 6, 1))\npadded_input = ZeroPadding2D(padding=((1, 0),(1,0)))(input_tensor)\nx = Conv2D(filters=1, kernel_size=3, strides=2)(padded_input)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T08:51:18.944927Z","iopub.execute_input":"2021-12-24T08:51:18.945245Z","iopub.status.idle":"2021-12-24T08:51:18.964796Z","shell.execute_reply.started":"2021-12-24T08:51:18.945214Z","shell.execute_reply":"2021-12-24T08:51:18.963971Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Maxpooling 적용","metadata":{}},{"cell_type":"code","source":"input_tensor = Input(shape=(223, 223, 1))\nx = MaxPooling2D(2)(input_tensor)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T08:51:21.006199Z","iopub.execute_input":"2021-12-24T08:51:21.006913Z","iopub.status.idle":"2021-12-24T08:51:21.018777Z","shell.execute_reply.started":"2021-12-24T08:51:21.006856Z","shell.execute_reply":"2021-12-24T08:51:21.017729Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}