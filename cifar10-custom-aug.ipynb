{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-13T13:09:33.553339Z","iopub.execute_input":"2022-01-13T13:09:33.553722Z","iopub.status.idle":"2022-01-13T13:09:33.582389Z","shell.execute_reply.started":"2022-01-13T13:09:33.553645Z","shell.execute_reply":"2022-01-13T13:09:33.581738Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\n\nimport random as python_random\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.datasets import cifar10\n\n# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \ndef set_random_seed(seed_value):\n    np.random.seed(seed_value)\n    python_random.seed(seed_value)\n    tf.random.set_seed(seed_value)\n\n# 0 ~ 1사이값의 float32로 변경하는 함수\ndef get_preprocessed_data(images, labels, scaling=True):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    if scaling:\n        images = np.array(images/255.0, dtype=np.float32)\n    else:\n        images = np.array(images, dtype=np.float32)\n        \n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\n# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \ndef get_preprocessed_ohe(images, labels):\n    images, labels = get_preprocessed_data(images, labels, scaling=False)\n    # OHE 적용 \n    oh_labels = to_categorical(labels)\n    return images, oh_labels\n\n# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \ndef get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n    \n    # 학습 데이터를 검증 데이터 세트로 다시 분리\n    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n    \n    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n\n\n# random seed는 2021로 고정.\nset_random_seed(2021)\n# CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\nprint(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n\n(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n\nprint(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T13:09:37.648784Z","iopub.execute_input":"2022-01-13T13:09:37.649199Z","iopub.status.idle":"2022-01-13T13:09:48.057995Z","shell.execute_reply.started":"2022-01-13T13:09:37.649162Z","shell.execute_reply":"2022-01-13T13:09:48.057147Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\n%matplotlib inline\n\nNAMES = np.array(['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n\ndef show_images(images, labels, ncols=8):\n    figure, axs = plt.subplots(figsize=(22, 6), nrows=1, ncols=ncols)\n    for i in range(ncols):\n        axs[i].imshow(images[i])\n        label = labels[i].squeeze()\n        axs[i].set_title(NAMES[int(label)])\n        \nshow_images(train_images[:8], train_labels[:8], ncols=8)\nshow_images(train_images[8:16], train_labels[8:16], ncols=8)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T13:10:38.808730Z","iopub.execute_input":"2022-01-13T13:10:38.809434Z","iopub.status.idle":"2022-01-13T13:10:40.597250Z","shell.execute_reply.started":"2022-01-13T13:10:38.809375Z","shell.execute_reply":"2022-01-13T13:10:40.596008Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tr_images[:10]","metadata":{"execution":{"iopub.status.busy":"2022-01-13T13:10:53.890799Z","iopub.execute_input":"2022-01-13T13:10:53.891056Z","iopub.status.idle":"2022-01-13T13:10:53.908537Z","shell.execute_reply.started":"2022-01-13T13:10:53.891028Z","shell.execute_reply":"2022-01-13T13:10:53.907628Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = 32\nBATCH_SIZE = 64","metadata":{"execution":{"iopub.status.busy":"2022-01-13T13:11:43.424942Z","iopub.execute_input":"2022-01-13T13:11:43.425205Z","iopub.status.idle":"2022-01-13T13:11:43.430181Z","shell.execute_reply.started":"2022-01-13T13:11:43.425175Z","shell.execute_reply":"2022-01-13T13:11:43.429391Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### ImageDataGenerator로 Augmentation 설정하고 학습용, 검증용 Generator 생성","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_generator = ImageDataGenerator(\n    #rotation_range=20,\n    #zoom_range=(0.7, 0.9),\n    horizontal_flip=True,\n    #vertical_flip=True,\n    rescale=1/255.0\n)\nvalid_generator = ImageDataGenerator(rescale=1/255.0) # valid 데이터용 제네레이터\n\nflow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\nflow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T13:21:15.052161Z","iopub.execute_input":"2022-01-13T13:21:15.052455Z","iopub.status.idle":"2022-01-13T13:21:15.086473Z","shell.execute_reply.started":"2022-01-13T13:21:15.052406Z","shell.execute_reply":"2022-01-13T13:21:15.085712Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Keras CNN 모델 생성. ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n\ndef create_model(verbose=False):\n    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n\n    #x = Conv2D(filters=32, kernel_size=(5, 5), padding='valid', activation='relu')(input_tensor)\n    x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(input_tensor)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n    x = Activation('relu')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D(pool_size=2)(x)\n\n    x = Conv2D(filters=256, kernel_size=3, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters=256, kernel_size=3, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters=512, kernel_size=3, strides=2, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    # Flatten 대신 Global AveragePooling 을 적용. \n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(rate=0.5)(x)\n    x = Dense(50, activation='relu', name='fc1')(x)\n    x = Dropout(rate=0.2)(x)\n    output = Dense(10, activation='softmax', name='output')(x)\n\n    model = Model(inputs=input_tensor, outputs=output)\n    if verbose:\n        model.summary()\n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-13T13:22:33.388646Z","iopub.execute_input":"2022-01-13T13:22:33.389387Z","iopub.status.idle":"2022-01-13T13:22:33.406767Z","shell.execute_reply.started":"2022-01-13T13:22:33.389349Z","shell.execute_reply":"2022-01-13T13:22:33.405996Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = create_model(verbose=True)\nmodel.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \nrlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\nely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T13:23:36.035896Z","iopub.execute_input":"2022-01-13T13:23:36.036199Z","iopub.status.idle":"2022-01-13T13:23:39.041662Z","shell.execute_reply.started":"2022-01-13T13:23:36.036169Z","shell.execute_reply":"2022-01-13T13:23:39.040386Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"image_batch, label_batch = next(flow_tr_gen)\nprint(image_batch.shape, label_batch.shape)\nprint(image_batch[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=32, epochs=30, shuffle=True,\n                    validation_data=(val_images, val_oh_labels),  \n                    callbacks=[rlr_cb, ely_cb] )\n'''\n# steps 횟수를 구하기 위해 학습 데이터의 건수와 검증 데이터의 건수를 구함. steps = ceil(학습 데이터 건수/BATCH_SIZE)\ntr_data_len = tr_images.shape[0]\nval_data_len = val_images.shape[0]\nhistory = model.fit(flow_tr_gen, epochs=40,   # 데이터의 입력 및 집어넣는 과정은 제너레이터가 담당한다.\n                    steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)), # steps = 배치가 몇번 움직여야 전체 학습 데이터를 가져오느냐. 즉, 이건 한 이포크당 step을 몇번 적용할지.\n                    validation_data=flow_val_gen, \n                    validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n                    callbacks=[rlr_cb, ely_cb])","metadata":{"execution":{"iopub.status.busy":"2022-01-13T13:34:23.752234Z","iopub.execute_input":"2022-01-13T13:34:23.752502Z","iopub.status.idle":"2022-01-13T13:39:34.908258Z","shell.execute_reply.started":"2022-01-13T13:34:23.752471Z","shell.execute_reply":"2022-01-13T13:39:34.907486Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"test_generator = ImageDataGenerator(rescale=1/255.0)\nflow_test_gen = test_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\nmodel.evaluate(flow_test_gen)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T13:51:08.418512Z","iopub.execute_input":"2022-01-13T13:51:08.419237Z","iopub.status.idle":"2022-01-13T13:51:09.515166Z","shell.execute_reply.started":"2022-01-13T13:51:08.419203Z","shell.execute_reply":"2022-01-13T13:51:09.514468Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_history(history):\n    plt.figure(figsize=(8, 4))\n    plt.yticks(np.arange(0, 1, 0.05))\n    plt.xticks(np.arange(0, 30, 2))\n    plt.plot(history.history['accuracy'], label='train')\n    plt.plot(history.history['val_accuracy'], label='valid')\n    plt.legend()\n    \nshow_history(history)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T13:51:54.151558Z","iopub.execute_input":"2022-01-13T13:51:54.152297Z","iopub.status.idle":"2022-01-13T13:51:54.396266Z","shell.execute_reply.started":"2022-01-13T13:51:54.152249Z","shell.execute_reply":"2022-01-13T13:51:54.395478Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### 원본 이미지 상황에 맞지 않거나 과도한 Augmentation은 오히려 성능을 저하시킴.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_generator = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=(0.7, 0.9), # 원본 이미지 자체의 선명도(화질)이 떨어지는데 여기서 더 줌 땡겨버리면 자동차 같으면 창문 없이 본네트만 나와서 잘못된 학습 예시가 된다.\n    horizontal_flip=True,\n    vertical_flip=True,\n    rescale=1/255.0\n)\n\nvalid_generator = ImageDataGenerator(rescale=1/255.0)\n\nflow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True) # 모델에 데이터를 공급하는 역할.\nflow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n\nmodel = create_model()\nmodel.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \nrlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\nely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n\n# steps 횟수를 구하기 위해 학습 데이터의 건수와 검증 데이터의 건수를 구함. steps = ceil(학습 데이터 건수/BATCH_SIZE)\ntr_data_len = tr_images.shape[0]\nval_data_len = val_images.shape[0]\n\nhistory = model.fit(flow_tr_gen, epochs=40, \n                    steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)),\n                    validation_data=flow_val_gen, \n                    validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n                    callbacks=[rlr_cb, ely_cb], verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-13T13:55:52.219021Z","iopub.execute_input":"2022-01-13T13:55:52.219292Z","iopub.status.idle":"2022-01-13T14:12:31.175021Z","shell.execute_reply.started":"2022-01-13T13:55:52.219262Z","shell.execute_reply":"2022-01-13T14:12:31.174294Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#CPU 에서 numpy를 tensor로 다 바꾸고 gpu로 넘겨줘야 하는데 (배치 사이즈만큼), 근데 지금 cpu에서 augmentation을 하느라 많아야 1초? 정도 더 소요되는 바람에 전체적인 utilization이 떨어진다.\n\ntest_generator = ImageDataGenerator(rescale=1/255.0)\nflow_test_gen = test_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\nmodel.evaluate(flow_test_gen)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T14:12:49.670286Z","iopub.execute_input":"2022-01-13T14:12:49.670670Z","iopub.status.idle":"2022-01-13T14:12:50.828904Z","shell.execute_reply.started":"2022-01-13T14:12:49.670628Z","shell.execute_reply":"2022-01-13T14:12:50.828226Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}